{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:  \n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply the distortion correction to the raw image.  \n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\"). \n",
    "* Detect lane pixels and fit to find lane boundary.\n",
    "* Determine curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images\n",
    "\n",
    "In the cell below, I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world... I'll assume the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time we successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.  ```objpoints``` and `imgpoints` are the relevant output of this cell, and will be used for computing the camera calibration.\n",
    "\n",
    "---\n",
    "Note: run the next cell to get code highlighting in the markdown cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> code {background-color : pink !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style> code {background-color : pink !important;} </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../images_video/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## camera calibration\n",
    "\n",
    "Here I'll use the `cv2.calibrateCamera()` function to compute the camera matrix, distortion coefficients, and rotational and translational matrices (though I won't use these last two for anything).  I'll save the camera matrix and distortion coefficients in a pickled dictionary.  \n",
    "\n",
    "To visualize that the camera calibration worked, I'll apply the `cv2.undistort()` function to a test image and display it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('../images_video/calibration1.jpg')\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('../images_video/cal1_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions to perform the steps of the lane finding pipeline\n",
    "\n",
    "First, I'll define the functions for warping images and points.  `warper()` takes in an image and returns a warped image based on the source (`src`) and destination (`dst`) image points provided using `cv2.getPerspectiveTransform()` and `cv2.warpPerspective()`.  `warp_points()` takes vectors of x and y points and warps them based on a particular perspective transform matrix.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some functions to do perspective transform\n",
    "\n",
    "def warper(binary_img):\n",
    "\n",
    "    # Define calibration box in source (actual) and destination (desired) coordinates\n",
    "    img_size = (binary_img.shape[1], binary_img.shape[0])\n",
    "    src = np.float32(\n",
    "        [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "         [((img_size[0] / 6) - 10), img_size[1]],\n",
    "         [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "         [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])\n",
    "    dst = np.float32(\n",
    "        [[(img_size[0] / 4), 0],\n",
    "         [(img_size[0] / 4), img_size[1]],\n",
    "         [(img_size[0] * 3 / 4), img_size[1]],\n",
    "         [(img_size[0] * 3 / 4), 0]])\n",
    "\n",
    "    # Compute and apply perpective transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv =  cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(binary_img, M, img_size, flags=cv2.INTER_NEAREST)  # keep same size as input image\n",
    "\n",
    "    return Minv, warped\n",
    "\n",
    "# Define a function to take x,y vectors of arbitrary length and warp to new space given transform matrix M\n",
    "def warp_points(x, y, M):\n",
    "    # Expect x and y to be vectors and transform matrix M to be a 3x3\n",
    "    xnew = (M[0][0]*x + M[0][1]*y + M[0][2])/(M[2][0]*x + M[2][1]*y + M[2][2])\n",
    "    ynew = (M[1][0]*x + M[1][1]*y + M[1][2])/(M[2][0]*x + M[2][1]*y + M[2][2])\n",
    "    \n",
    "    return xnew, ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining more functions\n",
    "\n",
    "`region_of_interest()` is just like we used in the first project, masks an image given vertices of a polygon\n",
    "\n",
    "`find_line_pixels()`, `line_search()`, and `find_newgood()` together comprise a hacky way of taking a warped binary image and finding which pixels represent the lane lines and fitting them with a quadratic to determine curvature etc.  The basic idea is that if the left or right line is undetected (`line.detected = False`), then I'll search for the line using a histogram by summing the bottom half of the image along columns (left quadrant for left line or right quadrant for right line).  Once I detect line pixels, I'll fit a 2nd order polynomial and compute the curvature and vehicle position within the lane.  \n",
    "\n",
    "If enough detections exist from previous frames, I'll perform an outlier rejection step as well to get rid of anomalous detections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \n",
    "    # Define a blank mask to start with\n",
    "    mask = np.zeros(img.shape, np.float) \n",
    "    \n",
    "    # Define a 3 channel or 1 channel fill color\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,)*channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Fill pixels inside the polygon defined by \"vertices\" with fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    # Return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask.astype(img.dtype))\n",
    "    return masked_image\n",
    "\n",
    "def find_newgood(nzerox, nzeroy, startind, stopind, width, fit):\n",
    "    \n",
    "    # Extrapolate a fit to the lane line to include new pixels\n",
    "    fitdeg = len(fit) - 1\n",
    "    if fitdeg == 2:\n",
    "        xfit = fit[0]*nzeroy**2 + fit[1]*nzeroy + fit[2]\n",
    "    elif fitdeg == 1:\n",
    "        xfit = fit[0]*nzeroy + fit[1] \n",
    "    good = ((nzerox >= (xfit - width)) \\\n",
    "                    & (nzerox <= (xfit + width)) \\\n",
    "                    & (nzeroy > startind) \\\n",
    "                    & (nzeroy <= stopind)).nonzero()[0]\n",
    "    return good\n",
    "\n",
    "def line_search(nzx, nzy, px, ystart_frac, startind, img_shape, margin):\n",
    "    \n",
    "    # Identify pixels associated with the base of the line (bottom of the image)\n",
    "    good1 = ((nzx >= px[0]) & (nzx <= px[1]) & (nzy >= startind)).nonzero()[0]\n",
    "    nonzero1x = nzx[good1]  \n",
    "    nonzero1y = nzy[good1]    \n",
    "\n",
    "    # Define the starting point for bins in y to iteratively find the lines\n",
    "    next_ysfrac = ystart_frac - 0.1\n",
    "    last_ysfrac = 0\n",
    "    nsteps = 1 + next_ysfrac/0.1\n",
    "    ystarts = np.linspace(next_ysfrac, last_ysfrac, nsteps, endpoint=True)\n",
    "    dy = 1 - ystart_frac # y bin size\n",
    "   \n",
    "    for ys in ystarts:  # step through the bins in y\n",
    "        \n",
    "        order = 1    # order of the polynomial fit        \n",
    "        line1 = np.polyfit(nonzero1y, nonzero1x, order) # fit a line to pixels in the base of left line\n",
    "        startind = round(img_shape[0]*ys)   # start point of y bin\n",
    "        stopind = round(img_shape[0]*(ys+dy))  # end point of y bin\n",
    "        #select new set of pixels to add to the line\n",
    "        new_good1 = find_newgood(nzx, nzy, startind, stopind, margin, line1)  \n",
    "        if len(new_good1) > 0:  #if we found some, add them to the line\n",
    "            if len(new_good1) > 10: #if we found more than 10 use them to define next line segment selection\n",
    "                nonzero1x = nzx[new_good1]\n",
    "                nonzero1y = nzy[new_good1]\n",
    "            \n",
    "            good1 = np.hstack((good1, new_good1))    \n",
    "        \n",
    "    \n",
    "    # Get rid of duplicates from overlapping bins\n",
    "    return np.unique(good1)\n",
    "\n",
    "# Define the main function for finding the lines, either based on previous detection or blind search\n",
    "def find_line_pixels(binimg):\n",
    "    \n",
    "    # Define some parameters for line search, if lines not already detected\n",
    "    img_shape = binimg.shape\n",
    "    search_smooth = 11\n",
    "    ystart_frac = 0.5\n",
    "    ymid = np.int(img_shape[0]/2)\n",
    "    xmid = np.int(img_shape[1]/2)\n",
    "    \n",
    "    margin = 50 # width to include pixels left and right of the fit\n",
    "    min_detected_pixels = 10 #arbitrary cutoff for minimum number of pixels defining a line\n",
    "    \n",
    "    # Identify all nonzero pixels in the binary image\n",
    "    nonzero = binimg.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # If the left line was detected in the previous frame, search for new detection within +/- margin in x\n",
    "    if left_line.detected:\n",
    "        leftfit = left_line.best_fit\n",
    "        # Identify all pixels associated with the lines\n",
    "        good_inds = ((nonzerox > (leftfit[0]*(nonzeroy**2) + leftfit[1]*nonzeroy + leftfit[2] - margin)) & \\\n",
    "                    (nonzerox < (leftfit[0]*(nonzeroy**2) + leftfit[1]*nonzeroy + leftfit[2] + margin)))  \n",
    "        \n",
    "        if len(good_inds) > min_detected_pixels: \n",
    "            left_line.allx = nonzerox[good_inds]\n",
    "            left_line.ally = nonzeroy[good_inds]\n",
    "            left_fit = np.polyfit(left_line.ally, left_line.allx, 2)\n",
    "            left_line.detected = True\n",
    "        else:\n",
    "            left_line.detected = False\n",
    "      \n",
    "    else: \n",
    "        # Search the lower left quadrant of the image for the left line base\n",
    "        print('initializing search for left line...')\n",
    "        counts = np.sum(binimg[ymid:, 0:xmid], axis=0) #histogram of hot pixels in each column of pixels\n",
    "        smooth_counts = np.convolve(counts, np.ones(search_smooth)/search_smooth, mode='same') #boxcar smooth\n",
    "        line_cen = np.argmax(smooth_counts)\n",
    "        pleftx = [line_cen - margin, line_cen + margin]\n",
    "        good_inds = line_search(nonzerox, nonzeroy, pleftx, ystart_frac, ymid, img_shape, margin)                \n",
    "\n",
    "        if len(good_inds) > min_detected_pixels: \n",
    "            left_line.allx = nonzerox[good_inds]\n",
    "            left_line.ally = nonzeroy[good_inds]\n",
    "            left_fit = np.polyfit(left_line.ally, left_line.allx, 2)\n",
    "            left_line.detected = True\n",
    "        else:\n",
    "            left_line.detected = False\n",
    "\n",
    "    # If the right line was detected in the previous frame, search for new detection within +/- margin in x\n",
    "    if right_line.detected:        \n",
    "        rightfit = right_line.best_fit\n",
    "        # Identify all pixels associated with the lines\n",
    "        good_inds = ((nonzerox > (rightfit[0]*(nonzeroy**2) + rightfit[1]*nonzeroy + rightfit[2] - margin)) & \\\n",
    "                     (nonzerox < (rightfit[0]*(nonzeroy**2) + rightfit[1]*nonzeroy + rightfit[2] + margin)))\n",
    "        if len(good_inds) > min_detected_pixels: \n",
    "            right_line.allx = nonzerox[good_inds]\n",
    "            right_line.ally = nonzeroy[good_inds]\n",
    "            right_fit = np.polyfit(right_line.ally, right_line.allx, 2)\n",
    "            right_line.detected = True\n",
    "        else:\n",
    "            right_line.detected = False\n",
    "      \n",
    "    else: \n",
    "        # Search the lower left quadrant of the image for the left line base\n",
    "        print('initializing search for the right line...')\n",
    "        counts = np.sum(binimg[ymid:, xmid:], axis=0) #histogram of hot pixels in each column of pixels\n",
    "        smooth_counts = np.convolve(counts, np.ones(search_smooth)/search_smooth, mode='same') #boxcar smooth\n",
    "        line_cen = np.argmax(smooth_counts) + xmid\n",
    "        prightx = [line_cen - margin, line_cen + margin]\n",
    "        good_inds = line_search(nonzerox, nonzeroy, prightx, ystart_frac, ymid, img_shape, margin)                \n",
    "\n",
    "        if len(good_inds) > min_detected_pixels: \n",
    "            right_line.allx = nonzerox[good_inds]\n",
    "            right_line.ally = nonzeroy[good_inds]\n",
    "            right_fit = np.polyfit(right_line.ally, right_line.allx, 2)\n",
    "            right_line.detected = True\n",
    "        else:\n",
    "            right_line.detected = False\n",
    "            \n",
    "\n",
    "    recent_detections = 10 #an arbitrary number of recent detections to take into consideration when deciding\n",
    "                            #whether a new detection is an outlier\n",
    "    if left_line.detected:\n",
    "        \n",
    "        # Take the difference in fit coefficients between last fit and new fit\n",
    "        diff_left = np.absolute(left_line.current_fit - left_fit)\n",
    "        left_line.diffs = np.vstack((left_line.diffs, diff_left))\n",
    "        \n",
    "        # If we have enough data do the outlier rejection step\n",
    "        if left_line.diffs.shape[0] > recent_detections:\n",
    "            left_std = np.std(left_line.diffs[:,0])\n",
    "            left_line.diffs = left_line.diffs[-recent_detections:]\n",
    "            \n",
    "            # Reject outliers where quadratic term of the fit is > 4 standard devs from best fit\n",
    "            if diff_left[0] < 4*left_std:\n",
    "                left_line.current_fit = left_fit\n",
    "        else:\n",
    "            left_line.current_fit = left_fit\n",
    "     \n",
    "    if right_line.detected:\n",
    "        \n",
    "        # Take the difference in fit coefficients between last fit and new fit\n",
    "        diff_right = np.absolute(right_line.current_fit - right_fit)\n",
    "        right_line.diffs = np.vstack((right_line.diffs, diff_right))\n",
    "                    \n",
    "        if right_line.diffs.shape[0] > recent_detections:\n",
    "            right_std = np.std(right_line.diffs[:,0])\n",
    "            right_line.diffs = right_line.diffs[-recent_detections:]\n",
    "            if diff_right[0] < 4*right_std:\n",
    "                right_line.current_fit = right_fit                \n",
    "        else:\n",
    "            right_line.current_fit = right_fit\n",
    "\n",
    "        \n",
    "    sample_loc = img_shape[0]*0.5\n",
    "    left_curverad = ((1 + (2*left_fit[0]*sample_loc + left_fit[1])**2)**1.5)/np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*sample_loc + right_fit[1])**2)**1.5)/np.absolute(2*right_fit[0])\n",
    "    pixels_to_meters = 720/30  #this is wrong\n",
    "    avg_curverad = (left_curverad + right_curverad)/2/pixels_to_meters\n",
    "    left_line.radius_of_curvature = avg_curverad\n",
    "    left_line.deg_per_meter = 360/(2*np.pi*avg_curverad)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class to store the lane line characteristics\n",
    "\n",
    "Nothing special here, just creating a place to store and update measurements as I go.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.detected = False  # was the line detected in the last iteration?\n",
    "        self.recent_xfitted = [] # x values of the last n fits of the line\n",
    "        self.bestx = None     #average x values of the fitted line over the last n iterations\n",
    "        self.best_fit = None   #polynomial coefficients averaged over the last n iterations\n",
    "        self.current_fit = [np.array([False])]  #polynomial coefficients for the most recent fit\n",
    "        self.radius_of_curvature = None #radius of curvature of the line in some units\n",
    "        self.deg_per_meter = None   #degrees of curvature per meter (or some other units, pixels etc.)\n",
    "        self.line_base_pos = None #distance in meters of vehicle center from the line\n",
    "        self.diffs = np.array([0,0,0], dtype='float') #difference in fit coefficients between last and new fits\n",
    "        self.line_yvals = None    #y values that correspond to x values in self.bestx / line_xvals\n",
    "        self.line_xvals = None   #x values for fitted line corresponding to self.line_yvals\n",
    "        self.allx = None  #x values for detected line pixels\n",
    "        self.ally = None  #y values for detected line pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the `process_image()` function as a pipeline for image processing\n",
    "\n",
    "This is where everything gets stitched together.  Here, I'll take a frame of video and:\n",
    "\n",
    "* apply a distortion correction\n",
    "* do region masking\n",
    "* grayscale and take an x-derivative\n",
    "* do a color selection\n",
    "* threshold gradient and color can combine to make a binary image\n",
    "* warp binary and find lane pixels\n",
    "* fit lane pixels with polynomial and reject outliers\n",
    "* estimate curvature, vehicle position\n",
    "* use a low-pass filter to update lane position given new detection and previous detections\n",
    "* map the lane down onto the road and print out measurements to screen (curvature / vehicle pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the pipeline to process each image\n",
    "\n",
    "def process_image(image):\n",
    "\n",
    "    img_shape = image.shape\n",
    "    # Undistort the image per camera calibration\n",
    "    dst = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Grayscale and derivatives (no longer Gaussian smoothing)\n",
    "    gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abssx = np.absolute(sobelx) # Absolute x derivative to accentuate strong verticalish lines\n",
    "    scale_factor = np.max(abssx)/255 # Will use this to scale back to 8-bit scale\n",
    "    abssx = (abssx/scale_factor).astype(np.uint8) #rescaling to 8-bit \n",
    "    masked_abssx = region_of_interest(abssx, new_dict['vertices']) # and masking\n",
    "\n",
    "    masked_red = region_of_interest(dst[:,:,0], new_dict['vertices']) # Grab index 0 for red in RGB\n",
    "    #masked_red = region_of_interest(dst[:,:,2], new_dict['vertices']) # Grab index 2 for red in BGR\n",
    "    #masked_orig = region_of_interest(dst, new_dict['vertices']) # Mask original\n",
    "    \n",
    "    # Threshold x-gradient and red channel for lane pixel selection\n",
    "    retval, sxbinary = cv2.threshold(masked_abssx, 10, 100, cv2.THRESH_BINARY)\n",
    "    retval, redbinary = cv2.threshold(masked_red.astype('uint8'), 190, 255, cv2.THRESH_BINARY)\n",
    "    #retval, redbin = cv2.threshold(dst[:,:,2], 190, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Create a binary image where red channel or gradient above the threshold\n",
    "    redgrad_binary = np.clip(cv2.bitwise_or(redbinary, sxbinary), 0, 1).astype('uint8')\n",
    "\n",
    "    # Warp and calculate inverse warp matrix\n",
    "    Minv, warped = warper(redgrad_binary)\n",
    "\n",
    "    # Find lane pixels\n",
    "    find_line_pixels(warped)\n",
    "\n",
    "    # Generate lines to plot on warped image based on fit\n",
    "    yfit = np.linspace(0, img_shape[0] - 1, img_shape[0]).astype('int')\n",
    "    lfit = left_line.current_fit\n",
    "    rfit = right_line.current_fit\n",
    "    left_xfit = np.clip(np.round(lfit[0]*yfit**2 + lfit[1]*yfit + lfit[2]).astype('int'), 0, img_shape[1]-1)\n",
    "    right_xfit = np.clip(np.round(rfit[0]*yfit**2 + rfit[1]*yfit + rfit[2]).astype('int'), 0, img_shape[1]-1)\n",
    "\n",
    "    # Update the best fit if new lines were detected\n",
    "    # These next steps are effectively a \"low-pass filter\" \n",
    "    # I first update the list of recent detections with the latest detection\n",
    "    # Then average the position of the line based on the last smooth=5 detections\n",
    "    \n",
    "    smooth = 5\n",
    "    if left_line.detected:\n",
    "        if len(left_line.recent_xfitted) > 0:\n",
    "            left_line.recent_xfitted.append(left_xfit)\n",
    "        else:\n",
    "            left_line.recent_xfitted = [left_xfit]\n",
    "\n",
    "        if len(left_line.recent_xfitted) > smooth:\n",
    "            left_line.recent_xfitted = left_line.recent_xfitted[-smooth:]   \n",
    "        left_line.bestx = np.mean(np.array(left_line.recent_xfitted), axis=0).astype('int')\n",
    "        left_line.best_fit = np.polyfit(yfit, left_line.bestx, 2)\n",
    "        left_line.line_xvals = left_xfit #grab the left position of the most recent lane\n",
    "        left_line.line_yvals = yfit\n",
    "        \n",
    "    if right_line.detected:\n",
    "        if len(right_line.recent_xfitted) > 0:\n",
    "            right_line.recent_xfitted.append(right_xfit)\n",
    "        else:\n",
    "            right_line.recent_xfitted = [right_xfit]\n",
    "\n",
    "        if len(right_line.recent_xfitted) > smooth:\n",
    "            right_line.recent_xfitted = right_line.recent_xfitted[-smooth:]   \n",
    "        right_line.bestx = np.mean(np.array(right_line.recent_xfitted), axis=0).astype('int')\n",
    "        right_line.best_fit = np.polyfit(yfit, right_line.bestx, 2)\n",
    "        right_line.line_xvals = right_xfit #grab the right position of the most recent lane\n",
    "        right_line.line_yvals = yfit\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Generating some \"slides\" to plot color lines\n",
    "    warp_copy1 = np.zeros(warped.shape, dtype='uint8')\n",
    "    warp_copy2 = np.zeros(warped.shape, dtype='uint8')\n",
    "    warp_copy3 = np.zeros(warped.shape, dtype='uint8')\n",
    "\n",
    "    # plot right and left lines\n",
    "    #warp_copy1[yfit, left_xfit] = 255\n",
    "    #warp_copy1[yfit, right_xfit] = 255\n",
    "    warp_copy2[left_line.ally, left_line.allx] = 255\n",
    "    warp_copy3[right_line.ally, right_line.allx] = 255\n",
    "    color_binary = np.dstack((warp_copy2, warp_copy1, warp_copy3)) \n",
    "    color_warped = np.dstack((warped, warped, warped))\n",
    "    binresult = cv2.addWeighted(color_warped, 0.7, color_binary, 1, 0)\n",
    "\n",
    "    # Unwarp slides back to image space\n",
    "    unwarp_copy1 = cv2.warpPerspective(warp_copy1, Minv, \n",
    "                                       (img_shape[1], img_shape[0]), \n",
    "                                       flags=cv2.INTER_NEAREST)\n",
    "    unwarp_copy2 = cv2.warpPerspective(warp_copy2, Minv, \n",
    "                                       (img_shape[1], img_shape[0]), \n",
    "                                       flags=cv2.INTER_NEAREST)\n",
    "    unwarp_copy3 = cv2.warpPerspective(warp_copy3, Minv, \n",
    "                                       (img_shape[1], img_shape[0]), \n",
    "                                       flags=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Unwarp fitted line pixels\n",
    "    unwarp_xpix_left, unwarp_ypix  = warp_points(left_line.bestx, yfit, Minv)\n",
    "    unwarp_xpix_right, unwarp_ypix  = warp_points(right_line.bestx, yfit, Minv)\n",
    "    left_line.line_base_pos = unwarp_xpix_left[-1]\n",
    "    right_line.line_base_pos = unwarp_xpix_right[-1]\n",
    "    \n",
    "    # Find top and bottom of the fitted lines\n",
    "    top = np.min(unwarp_ypix) \n",
    "    bottom = np.max(unwarp_ypix)\n",
    "\n",
    "    # Create an array of y points to interpolate the fit in image space\n",
    "    n_ypts = bottom - top + 1      \n",
    "    interp_y = np.linspace(top, bottom, n_ypts).astype('int')\n",
    "    interp_xleft = np.round(np.interp(interp_y, unwarp_ypix, unwarp_xpix_left)).astype('int') \n",
    "    interp_xright = np.round(np.interp(interp_y, unwarp_ypix, unwarp_xpix_right)).astype('int')\n",
    "        \n",
    "    # Get our fitted lane lines into shape for cv2.fillPoly\n",
    "    pts_left = np.array([np.transpose(np.vstack([interp_xleft, interp_y]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([interp_xright, interp_y])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Create new set of vertices to set the region of interest to some margin around the lane\n",
    "    top_window_extend = 20\n",
    "    adjust = (interp_y - np.min(interp_y))/3\n",
    "    offset = (adjust + top_window_extend).astype('int')\n",
    "    verts_left = np.array([np.transpose(np.vstack([interp_xleft-offset, interp_y]))])\n",
    "    verts_right = np.array([np.flipud(np.transpose(np.vstack([interp_xright+offset, interp_y])))])\n",
    "    verts = np.hstack((verts_left, verts_right))\n",
    "    new_dict['vertices'] = verts\n",
    "\n",
    "    # Create some slides to draw lane on\n",
    "    line_drawn1 = np.zeros_like(unwarp_copy1)\n",
    "    line_drawn2 = np.zeros_like(unwarp_copy1)\n",
    "    line_drawn3 = np.zeros_like(unwarp_copy1)\n",
    "    \n",
    "    # Create a mask to fill the area between the left and right lines\n",
    "    cv2.fillPoly(line_drawn2, pts, 255)\n",
    "\n",
    "    # Create some color images to show lane detection\n",
    "    # First, just a green polygon covering the lane area\n",
    "    lane_unwarp = np.dstack((line_drawn1, line_drawn2, line_drawn3)).astype('uint8')\n",
    "    # Show the left lane pixels in red and the right lane pixels in blue (or vice versa in BGR space)\n",
    "    leftright_unwarp = np.dstack((unwarp_copy2, line_drawn1, unwarp_copy3)).astype('uint8')\n",
    "    # Paint the lines and lane area back on the road\n",
    "    line_result = cv2.addWeighted(dst, 1, lane_unwarp, 0.3, 0)\n",
    "    line_lr_result = cv2.addWeighted(line_result, 0.7, leftright_unwarp, 1, 0)\n",
    "    \n",
    "    # Text output for radius of curvature and vehicle position\n",
    "    curve_string = str(np.int(left_line.radius_of_curvature))\n",
    "    cv2.putText(line_lr_result,\"Radius of Curvature = \" + curve_string + '(m)', (50,50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "    center = image.shape[1]/2\n",
    "    pix_to_meter = 1280/3 #here I'm guessing that the base of the image is 3 meters wide\n",
    "    vehicle_pos = round((center - (left_line.line_base_pos+right_line.line_base_pos)/2)/pix_to_meter, 2)\n",
    "    if vehicle_pos < 0:\n",
    "        pos_string = ' left of center'\n",
    "    else: \n",
    "        pos_string = ' right of center'\n",
    "    \n",
    "    cv2.putText(line_lr_result,\"Vehicle is \" + str(np.absolute(vehicle_pos)) + 'm' + pos_string, (50,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "\n",
    "    #Minv, warped_orig = warper(image)\n",
    "    #return warped\n",
    "    #return redgrad_binary\n",
    "    #return binresult\n",
    "    return line_lr_result\n",
    "    #return redbin\n",
    "    #return masked_orig\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, I'll test the pipeline on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to test the pipeline on a single image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Unpack camera calibration data\n",
    "dist_pickle = pickle.load( open( \"dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Define initial region of interest\n",
    "vertices = np.array([[(110,719), (625, 430), (680, 430), (1260, 719)]], dtype=np.int32)\n",
    "new_dict = {'vertices':vertices}\n",
    "\n",
    "# Create some new Line objects\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img = mpimg.imread('../images_video/bridge_trees_example.jpg')\n",
    "#img = mpimg.imread('../images_video/solidWhiteRight.jpg')\n",
    "out = process_image(img)\n",
    "plt.imshow(out)#, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## In the next cell, I'm running the pipeline and displaying the results frame by frame in an openCV window.  To process the entire video and output to file, move to the next cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to watch the video processing frame by frame in an OpenCV window \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "# Unpack camera calibration data\n",
    "dist_pickle = pickle.load( open( \"dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Define initial region of interest\n",
    "vertices = np.array([[(110,719), (625, 430), (680, 430), (1260, 719)]], dtype=np.int32)\n",
    "new_dict = {'vertices':vertices}\n",
    "\n",
    "# Create some new Line objects\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "# Start up OpenCV window\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('Lane-Finding')\n",
    "cv2.moveWindow('Lane-Finding', 0, 0)\n",
    "\n",
    "#cv2.namedWindow('Lane-Finding2')\n",
    "#cv2.moveWindow('Lane-Finding2', 640, 0)\n",
    "\n",
    "#cv2.namedWindow('Lane-Finding3')\n",
    "#cv2.moveWindow('Lane-Finding3', 0, 400)\n",
    "\n",
    "#cap = cv2.VideoCapture('../images_video/Full_frame_Highway.mp4')\n",
    "cap = cv2.VideoCapture('../images_video/bridge_shadow_Highway.mp4')\n",
    "#cap = cv2.VideoCapture('../images_video/curvy_mountain.mp4')\n",
    "#cap = cv2.VideoCapture('../images_video/Uncut_Highway.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        output = process_image(image)\n",
    "        #reout = cv2.resize(np.dstack((output, output, output)).astype(np.uint8), (640, 360))\n",
    "        reout = cv2.resize(cv2.cvtColor(output, cv2.COLOR_BGR2RGB), (640, 360))\n",
    "        cv2.imshow('Lane-Finding', reout)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## In the next cell I'm using moviepy to process the entire video and output to file  Run this cell and check out test.mp4 to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to process an entire video with moviepy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Unpack camera calibration data\n",
    "dist_pickle = pickle.load( open( \"dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Define initial region of interest\n",
    "vertices = np.array([[(110,719), (625, 430), (680, 430), (1260, 719)]], dtype=np.int32)\n",
    "new_dict = {'vertices':vertices}\n",
    "\n",
    "# Create some new Line objects\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "test_output = 'test.mp4'\n",
    "clip = VideoFileClip(\"../images_video/challenge.mp4\")\n",
    "#clip = VideoFileClip(\"../images_video/bridge_shadow_Highway.mp4\")\n",
    "#clip = VideoFileClip(\"../images_video/curvy_mountain.mp4\")\n",
    "test_clip = clip.fl_image(process_image)\n",
    "#%time \n",
    "test_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Display the result from moviepy by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
